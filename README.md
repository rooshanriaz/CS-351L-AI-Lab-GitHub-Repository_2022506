# CS-351-AI-Lab

Welcome to the **CS-351 AI Lab** repository! This project contains implementations of various AI algorithms as part of the CS-351 AI Lab course. Each lab showcases different algorithms applied to solve problems using classic and heuristic search techniques.

## Table of Contents

- [Lab 1: Introduction to Artificial Intelligence and Python Basics](#lab-1-introduction-to-artificial-intelligence-and-python-basics)
  - [BFS](#bfs)
  - [DFS](#dfs)
  - [Simulated Annealing](#simulated-annealing)
- [Lab 2: Introduction to Search in AI](#lab-2-introduction-to-search-in-ai)
- [Lab 3: Constraint Satisfaction Problems](#lab-3-constraint-satisfaction-problems)
- [Lab 4: k-Nearest Neighbors (k-NN) & Decision Trees](#lab-4-k-nearest-neighbors-(knn)-&-decision-trees)
- [Lab 8: Neural Networks](#lab-8-neural-networks)

- [License](#license)

## Lab 1: Introduction to Artificial Intelligence and Python Basics

In this lab, I implemented and tested various search algorithms on a number guessing game:

#### BFS

**Breadth-First Search (BFS)** explores all nodes at the present depth level before moving on to nodes at the next depth level. It is a complete and optimal search strategy for finite spaces.

#### DFS

**Depth-First Search (DFS)** explores as far down as possible along a branch before backtracking. It is more memory-efficient but may not always find the optimal solution in large search spaces.

#### Simulated Annealing

**Simulated Annealing** is a probabilistic technique that approximates the global optimum of a given function. It is especially useful for optimization problems with large, complex search spaces.

## Lab 2: Introduction to Search in AI

In this lab, I implemented the **A* Search Algorithm** to solve the Maze Runner game. A* is an informed search algorithm that uses heuristics to estimate the cost of reaching the goal, making it both complete and optimal under certain conditions.

## Lab 3: Constraint Satisfaction Problems

In this lab, I implemented CSP on an activity scheduling problem, which enables multiple individuals to schedule their activities according to time constraints.

## Lab 4: k-Nearest Neighbors (k-NN) & Decision Trees

In this task, I predicted whether passengers survived the Titanic disaster using the k-Nearest Neighbors (k-NN) and Decision Tree algorithms. The dataset includes features like age, gender, ticket class, and fare. After data preprocessing and splitting into training and test sets, both models are trained and evaluated using performance metrics like accuracy, precision, recall, and F1-score. Finally, the models' decision boundaries and performance metrics are visualized for comparison.

## Lab 8: Neural Networks



## Contact

For any queries or assistance, feel free to reach out to the course instructor:

**Mr. Usama Arshad**  
[GitHub: usamajanjua9](https://github.com/usamajanjua9)

## üôã‚Äç‚ôÇÔ∏è Maintainer

This repository is maintained by:

**Rooshan Riaz**  
[GitHub: rooshanriaz](https://github.com/rooshanriaz)
